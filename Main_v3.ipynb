{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6ac785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/macrostomum/git_environment/IJM-internship/tools/Centriole_Characteristic.ipynb\n",
      "importing Jupyter notebook from /home/macrostomum/git_environment/IJM-internship/tools/ToolBox.ipynb\n",
      "importing Jupyter notebook from /home/macrostomum/git_environment/IJM-internship/tools/Midline_Edge_Reformater.ipynb\n",
      "importing Jupyter notebook from /home/macrostomum/git_environment/IJM-internship/tools/Extract_Experiment_Characteristic.ipynb\n",
      "importing Jupyter notebook from /home/macrostomum/git_environment/IJM-internship/tools/CNN_Tools.ipynb\n",
      "importing Jupyter notebook from /home/macrostomum/git_environment/IJM-internship/tools/Graphical_Tools.ipynb\n",
      "importing Jupyter notebook from /home/macrostomum/git_environment/IJM-internship/tools/Analysis_Tools.ipynb\n",
      "importing Jupyter notebook from /home/macrostomum/git_environment/IJM-internship/tools/Centriole_Detection.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Allow importation of the others notebook\n",
    "import import_ipynb\n",
    "\n",
    "# pyTorch: module for the neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# load excel files \n",
    "# note 13 April 2021: the module might be deprecated => yes only for .xls \n",
    "#import xlrd - Using pylightxl instead\n",
    "import pylightxl as xl\n",
    "\n",
    "# time tools\n",
    "from time import time, asctime\n",
    "\n",
    "# module that list all files in a input directory\n",
    "from glob import glob\n",
    " \n",
    "# module that open/save data as csv\n",
    "import csv\n",
    "\n",
    "#import asyncio   # note 13/04/2021, this module was already anotated: might be useless\n",
    "\n",
    "# Data Vizualisation module\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "#worm_segmentation imports. I cannot import worm_segmentation functions. This is a temporary solution.\n",
    "#import numpy as np\n",
    "#from skimage.morphology import skeletonize\n",
    "#from PIL import Image \n",
    "\n",
    "# helper function \n",
    "# note 13/04/2021 instead of * each function should be load independently\n",
    "from tools.Centriole_Characteristic import *\n",
    "from tools.Extract_Experiment_Characteristic import *\n",
    "from tools.CNN_Tools import *\n",
    "from tools.Graphical_Tools import *\n",
    "from tools.Centriole_Detection import *\n",
    "\n",
    "#from tools.worm_segmentation import *"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5cc8f2e5",
   "metadata": {},
   "source": [
    "# SIMPLY EXECUTE THE CELL ABOVE THEN BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7df7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 = analyse all data in a folder; 2 = analyse a specific file.2\n",
      "Paste file name to be analysed, without extensions: MAX_Mac_WT_Rootletin-G-02\n",
      "files to analyse:  [['./to_analyse/MAX_Mac_WT_Rootletin-G-02.xlsm', './to_analyse/MAX_Mac_WT_Rootletin-G-02.tif']]\n",
      "Tue May  4 10:41:24 2021\n",
      "Exl file loaded: ./to_analyse/MAX_Mac_WT_Rootletin-G-02.xlsm\n",
      "Tif file loaded: ./to_analyse/MAX_Mac_WT_Rootletin-G-02.tif\n",
      "load midline and edge from excel? 1 = yes, 0 = no. 1\n",
      "Tue May  4 10:41:32 2021: Edge and Midline reformated\n",
      "Tue May  4 10:41:32 2021: Image Loaded\n",
      "Tue May  4 10:41:34 2021: Differential of Gaussian performed\n"
     ]
    }
   ],
   "source": [
    "def import_data(choice = int(input('1 = analyse all data in a folder; 2 = analyse a specific file.'))):\n",
    "    files = [] \n",
    "    tif_list = []\n",
    "    xls_list = []\n",
    "    \n",
    "    if choice == 1:\n",
    "        tif_list = glob('./to_analyse/*.tif')\n",
    "        xls_list = glob('./to_analyse/*.xlsm')\n",
    "        \n",
    "    elif choice == 2:\n",
    "        file_name = input('Paste file name to be analysed, without extensions: ')\n",
    "        tif_list = ['./to_analyse/' + file_name + '.tif']          \n",
    "        xls_list = ['./to_analyse/' + file_name + '.xlsm']\n",
    "        \n",
    "    else:\n",
    "        print('Option provided was not understood. Try again.')\n",
    "        \n",
    "        \n",
    "    files = list(map(list, zip(xls_list, tif_list)))\n",
    "    print('files to analyse: ', files)\n",
    "    return files\n",
    "\n",
    "\n",
    "files = import_data() #store function's return in a variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def edge_and_midline_reformat(file):\n",
    "    pathExcel = file[0]\n",
    "    pathImg_100x = file[1]\n",
    "    \n",
    "    print(f\"{asctime()}\")\n",
    "    print(f\"Exl file loaded: {pathExcel}\")\n",
    "    print(f\"Tif file loaded: {pathImg_100x}\") \n",
    "    \n",
    "    # Are you just testing the angle compensation?\n",
    "    Test_Angle_Compensation = False\n",
    "\n",
    "    #problem = 'classification'\n",
    "    LOAD_MIDLINE_AND_EDGE_FROM_EXCEL = int(input('load midline and edge from excel? 1 = yes, 0 = no. ')) #useless line. Get from excel data\n",
    "\n",
    "    if LOAD_MIDLINE_AND_EDGE_FROM_EXCEL == 1:\n",
    "        db = get_xls_values(pathExcel)            #get_xls_values() opens excel file and loads the coordinates \n",
    "        x_mid = db['worm_midline']['x']\n",
    "        y_mid = db['worm_midline']['y']\n",
    "        x_edg = db['worm_edge']['x']\n",
    "        y_edg = db['worm_edge']['y']\n",
    "        \n",
    "        # Invert the y axis for edge and midline\n",
    "        newY_mid, newY_edg = [], [] \n",
    "        for y in y_mid:\n",
    "            newY_mid.append(-y) \n",
    "\n",
    "        for y in y_edg: \n",
    "            newY_edg.append(-y) \n",
    "\n",
    "        # 'skeleton' of the worm\n",
    "        worm = [x_mid, newY_mid, x_edg, newY_edg ]\n",
    "        \n",
    "    elif LOAD_MIDLINE_AND_EDGE_FROM_EXCEL == 0:   \n",
    "        midline, edge = extract_worm_edge(path_img_10x, nBlur = 2, quantile = 0.01)\n",
    "        worm = [midline[0], midline[1], edge[0], edge[1]]\n",
    "    \n",
    "    else:\n",
    "        print('Option provided was not understood. Try again.')\n",
    "    \n",
    "    # Reformat midline and Edge in a given number of segment and sulbsegment\n",
    "    midline_final = aggregate_segment_char(worm[0], worm[1], worm[2], worm[3], n_midline_seg = 50, n_sub_segment = 25, n_edge_seg = 200)\n",
    "\n",
    "    print(f'{asctime()}: Edge and Midline reformated')\n",
    "    \n",
    "    return midline_final\n",
    "\n",
    "\n",
    "midline_final = edge_and_midline_reformat(files[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def centriole_identification(pathImg_100x):# CENTRIOLES IDENTIFICATION\n",
    "    \n",
    "    # load the 100x image using OpenCV\n",
    "    img = cv2.imread(pathImg_100x, cv2.IMREAD_UNCHANGED)\n",
    "    print(f'{asctime()}: Image Loaded')\n",
    "\n",
    "    # Compute differential of Gaussian then Otsu thresholding to try to get a mask of the centriole\n",
    "    # return a binary image\n",
    "    dog_img = dog_and_otsu(img)\n",
    "    \n",
    "    img_to_save = Image.fromarray((dog_img * 255).astype(np.uint8)) #updated this line. PIL pckg does not support [0-1] \n",
    "    newPath = pathImg_100x[:-4] + '_dog_otsu.tif'\n",
    "    img_to_save.save(newPath)\n",
    "        \n",
    "    print(f'{asctime()}: Dog & Otsu computed ')\n",
    "\n",
    "    \n",
    "    # detect centriole using find_maxima algorithm \n",
    "    # note: find_maxima() is the implementation of the find_maxima module in imageJ\n",
    "    # return a binary image\n",
    "    find_maxima_img = find_maxima(img)\n",
    "    \n",
    "    img_to_save = Image.fromarray((find_maxima_img * 255).astype(np.uint8))  #updated this line\n",
    "    newPath = pathImg_100x[:-4] + '_find_maxima.tif'\n",
    "    img_to_save.save(newPath)\n",
    "\n",
    "    print(f'{asctime()}: Find Maxima Computed')\n",
    "\n",
    "    \n",
    "    # combine the 2 previous approaches to get the final \n",
    "    # return a binary image\n",
    "    combine_img = dog_img*find_maxima_img\n",
    "    \n",
    "    img_to_save = Image.fromarray((combine_img * 255).astype(np.uint8)) #updated this line\n",
    "    newPath = pathImg_100x[:-4] + '_centriole_detected.tif'\n",
    "    img_to_save.save(newPath)\n",
    "    \n",
    "    print(f'{asctime()}: Centriole detected')\n",
    "    \n",
    "    return combine_img, img\n",
    "\n",
    "combine_img = centriole_identification(files[0][1])[0]\n",
    "img = centriole_identification(files[0][1])[1]\n",
    "\n",
    "\n",
    "#CENTRIOLE ANGLE PREDICTION FUNCTION\n",
    "def centriole_angle_predictor(combine_img, img):\n",
    "    \n",
    "    if torch.cuda.is_available():                                  \n",
    "        device = torch.device('cuda')\n",
    "        print('Running on cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('Running on cpu')\n",
    "\n",
    "    # Loading the Neural Network (VGG_Schmidtea) and the Weight of the network ()\n",
    "    #13/04/2021: only classification is working\n",
    "    \n",
    "    #if problem == 'classification':\n",
    "    model = VGG_Schmidtea(n_classes = 72).to(device)\n",
    "    model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_classification.pth', map_location = device))\n",
    "   # else:\n",
    "       # model = VGG_Schmidtea(n_classes = 1).to(device)\n",
    "       # model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_regression.pth', map_location = device))\n",
    "\n",
    "    # Put the model in evaluation/prediction mode\n",
    "    model.eval()\n",
    "\n",
    "    # Extraction of coordinates where centrioles are\n",
    "    ypts, xpts = np.where(combine_img == 1)\n",
    "\n",
    "    a_list_of_centriole = []\n",
    "\n",
    "    x_shape, y_shape = img.shape[1], img.shape[0] \n",
    "    xlim, ylim  = x_shape - 16 , y_shape - 16\n",
    "    for i in range(len(ypts)):\n",
    "        x, y = xpts[i], ypts[i]\n",
    "\n",
    "        if y > 16 and x > 16 and y < ylim and x < xlim:\n",
    "            #centriole_extracted = img.crop((xpts[i], ypts[i], xpts[i] + 32, ypts[i] + 32))\n",
    "            centriole = img[y-16:y+16, x-16:x+16]\n",
    "            centriole = np.asarray(centriole, dtype = \"uint8\")\n",
    "            centriole = centriole.reshape(1 , 1, 32, 32)\n",
    "            # Inside predictor:\n",
    "            centriole = torch.from_numpy(centriole)\n",
    "            centriole = centriole.float().to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(centriole)\n",
    "\n",
    "            angle = output.max(1)[1]\n",
    "            angle = angle.numpy()\n",
    "\n",
    "            #print(centriole_extracted)\n",
    "            #angle = predictor(model, centriole_extracted, device, problem = 'classification')\n",
    "            a_list_of_centriole.append(((xpts[i], ypts[i]), angle[0]))\n",
    "    \n",
    "    print(f'{asctime()}: Centrioles angle predicted and compensated')\n",
    "    \n",
    "    return a_list_of_centriole\n",
    "\n",
    "a_list_of_centriole = centriole_angle_predictor(combine_img, img)\n",
    "\n",
    "\n",
    "def centriole_reposition_reorientation(a_list_of_centriole, pathImg_100x):\n",
    "\n",
    "    shiftX = db['image_shift']['x']\n",
    "    shiftY = db['image_shift']['y']\n",
    "\n",
    "    shifted_centriole_list = []\n",
    "\n",
    "    for a_centriole in a_list_of_centriole:\n",
    "        xShifted = a_centriole[0][0] + shiftX\n",
    "        yShifted = a_centriole[0][1] + shiftY\n",
    "        #if problem == 'classification':\n",
    "        shifted_centriole_list.append(((xShifted, -yShifted),a_centriole[1]*5+2.5))\n",
    "       # else:\n",
    "            #shifted_centriole_list.append(((xShifted, -yShifted),a_centriole[1]))\n",
    "\n",
    "\n",
    "    reoriented_centriole = []\n",
    "    for a_centriole in shifted_centriole_list:\n",
    "        tmp_list = list(centriole_characterizator(a_centriole, midline_final))\n",
    "        if db['worm_orientation'] == 'gauche' or db['worm_orientation'] == 'left':\n",
    "            tmp_list[-2] = 1 - tmp_list[-2]\n",
    "            tmp_list[-1] = math.degrees(math.atan2(-math.sin(math.radians(tmp_list[-1])), -math.cos(math.radians(tmp_list[-1]))))\n",
    "        tmp_list.insert(1,a_centriole[0][0])\n",
    "        tmp_list.insert(2,a_centriole[0][1])\n",
    "\n",
    "        reoriented_centriole.append(tmp_list)\n",
    "\n",
    "\n",
    "        # Save\n",
    "    newPath = pathImg_100x[:-4] + '_DATA.csv'\n",
    "    with open(newPath, 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(reoriented_centriole)\n",
    "\n",
    "    print(f'{asctime()}: Centriole Dataset reformated')\n",
    "    \n",
    "    return reoriented_centriole\n",
    "\n",
    "centriole_reposition_reorientation(a_list_of_centriole, files[0][1])\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    print_a_antero_posterior_result(reoriented_centriole, i, n_ante_post_segment = 5, a_lat_size = 0.1, a_lat_step = 0.05, save = True, path = files[0][1][:-4])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
