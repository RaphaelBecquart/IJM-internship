{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_Schmidtea(nn.Module):\n",
    "    \n",
    "        def __init__(self, n_classes=72):\n",
    "            super(VGG_Schmidtea, self).__init__()\n",
    "        \n",
    "            self.conv_1 = nn.Sequential(                                                      # 32 * 32\n",
    "                nn.Conv2d( 1,   64, kernel_size = 3, padding = 1),  \n",
    "                nn.Conv2d( 64,  64, kernel_size = 3, padding = 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.MaxPool2d(kernel_size = 2)) \n",
    "\n",
    "            self.conv_2 = nn.Sequential(                                                     # 16 * 16 \n",
    "                nn.Conv2d( 64, 128, kernel_size = 3, padding = 1),   \n",
    "                nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.MaxPool2d(kernel_size = 2))\n",
    "\n",
    "            self.conv_3 = nn.Sequential(                                                     # 8 * 8\n",
    "                nn.Conv2d(128, 256, kernel_size = 3, padding = 1),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.MaxPool2d(kernel_size = 2))\n",
    "\n",
    "            self.conv_4 = nn.Sequential(                                                     # 4 * 4 \n",
    "                nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n",
    "                nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
    "                nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.MaxPool2d(kernel_size = 2))\n",
    "\n",
    "            self.conv_5 = nn.Sequential(                                                     # 2 * 2\n",
    "                nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
    "                nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
    "                nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.MaxPool2d(kernel_size = 2))                                               # 1 * 1 \n",
    "\n",
    "\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(p = 0.25),\n",
    "                nn.Linear(512, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(4096),\n",
    "                nn.Dropout(p = 0.25),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(4096),\n",
    "                nn.Linear(4096, n_classes))\n",
    "\n",
    "             \n",
    "        def forward(self, x):\n",
    "            x = self.conv_1(x)\n",
    "            x = self.conv_2(x)\n",
    "            x = self.conv_3(x)\n",
    "            x = self.conv_4(x)\n",
    "            x = self.conv_5(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.classifier(x)\n",
    "                    \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_vector, accuracy_vector,  confusion_matrix, train_loader, device, problem, criterion, optimizer, epoch, n_class, log_interval=700000):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    if problem == 'classification':\n",
    "        train_loss, correct = 0, 0\n",
    "        conf_mat = torch.zeros(n_class, n_class)\n",
    "        \n",
    "    else:\n",
    "        train_loss, correct_5, correct_2_5, correct_1 = 0, 0, 0, 0\n",
    "        conf_mat = torch.zeros(n_class, n_class)\n",
    "        \n",
    "    \n",
    "    # Loop over each batch from the training set\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        # Copy data to GPU if needed\n",
    "        img = batch['image'].float().to(device)\n",
    "        if problem == 'classification':\n",
    "            angle = batch['angle'].long().to(device)\n",
    "        else: \n",
    "            angle = batch['angle'].float().to(device)         ### Not sure it's a float\n",
    "\n",
    "        # Zero gradient buffers\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # Pass data through the network\n",
    "        output = model(img)\n",
    "        \n",
    "        #pred = output.max(1)[1]     \n",
    "        #correct += pred.eq(angle).cpu().sum()\n",
    "\n",
    "        # Calculate loss      \n",
    "        if problem == 'classification':\n",
    "            loss = criterion(output, angle)\n",
    "            pred = output.max(1)[1]     \n",
    "            correct += pred.eq(angle).cpu().sum()\n",
    "            \n",
    "            train_loss += loss\n",
    "            \n",
    "            for a, p in zip(angle.view(-1), pred.view(-1)):\n",
    "                conf_mat[a.long(), p.long()] +=1\n",
    "\n",
    "        elif problem == 'regression_1':\n",
    "            loss = criterion(output, angle)\n",
    "            \n",
    "        elif problem == 'regression_2' or problem == 'regression_3':\n",
    "            angle = torch.deg2rad(angle.float())\n",
    "            loss = criterion(output, angle)\n",
    "        \n",
    "        elif problem == 'regression_4':\n",
    "            loss = criterion(output, angle)\n",
    "            \"\"\"\n",
    "                outs = torch.sin(output[:, 1])  # Prediction of the sinus\n",
    "                outc = torch.cos(output[:, 0])  # Prediction of the cosine\n",
    "                pred_angle = torch.atan2(outs, outc) # Get the pred_angle in Radians\n",
    "                angle = torch.deg2rad(angle.float())  # Transform the real angle in radians\n",
    "            \n",
    "                loss = criterion(output, angle)\n",
    "            \"\"\"\n",
    "                                  \n",
    "            #output = output.reshape(len(output))\n",
    "            #cos_output = torch.cos(torch.deg2rad(output.float()))\n",
    "            #cos_angle  = torch.cos(torch.deg2rad(angle.float()))\n",
    "            #sin_output = torch.sin(torch.deg2rad(output.float()))\n",
    "            #sin_angle  = torch.sin(torch.deg2rad(angle.float()))\n",
    "            #loss = criterion(cos_output, cos_angle) + criterion(sin_output, sin_angle)\n",
    "            \n",
    "        \"\"\"train_loss += loss  \n",
    "            \n",
    "            angle_5 = angle//72\n",
    "            output_5 = output//72\n",
    "            correct_5 += output_5.eq(angle_5).cpu().sum()\n",
    "            \n",
    "            angle_2_5 = angle//36\n",
    "            output_2_5 = output//36\n",
    "            correct_2_5 += output_2_5.eq(angle_2_5).cpu().sum()\n",
    "            \n",
    "            angle_1 = angle//1\n",
    "            output_1 = output//1\n",
    "            correct_1 += output_1.eq(angle_1).cpu().sum()\n",
    "            \n",
    "            for a, p in zip(angle_5.view(-1), output_5.view(-1)):\n",
    "                conf_mat[a.long(), p.long()] +=1\"\"\"\n",
    "\n",
    "                \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print advancement of the code\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(img), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "               \n",
    "    train_loss /= len(train_loader)\n",
    "    loss_vector.append(train_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loss_vector, accuracy_vector, confusion_matrix, validation_loader, device, problem, criterion, n_class, list_target):\n",
    "    '''\n",
    "    Input of the function:\n",
    "        model: neural network model in Pytorch\n",
    "        loss_vector: empty array with is assigned by the function\n",
    "        accuracy_vector: empty array with is assigned by the function\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if problem == 'classification':\n",
    "        val_loss, correct = 0, 0\n",
    "        conf_mat = torch.zeros(n_class, n_class)\n",
    "    else:\n",
    "        val_loss, correct_5, correct_2_5, correct_1 = 0, 0, 0, 0\n",
    "        conf_mat = torch.zeros(n_class, n_class)\n",
    "        \n",
    "    i = 0\n",
    "    for batch_idx, batch in enumerate(validation_loader):\n",
    "        i +=1\n",
    "        # Copy data to GPU if needed\n",
    "        img = batch['image'].float().to(device)\n",
    "        if problem == 'classification':\n",
    "            angle = batch['angle'].long().to(device)\n",
    "        else: \n",
    "            angle = batch['angle'].float().to(device)       ### Not sure it's a float\n",
    "            \n",
    "        output = model(img)\n",
    "        \n",
    "        toto = angle.flatten().cpu()\n",
    "        tete = output.flatten().cpu()\n",
    "        #list_target.append((toto, tete))\n",
    "        #list_target.append((angle.flatten().to('cpu'), output.flatten().to('cpu')))\n",
    "        \n",
    "        # Pass data through the network\n",
    "        with torch.no_grad():\n",
    "            if problem == 'classification':\n",
    "                pred = output.max(1)[1]\n",
    "                correct += pred.eq(angle).cpu().sum()\n",
    "                \n",
    "                val_loss += criterion(pred, angle) \n",
    "                \n",
    "                for a, p in zip(angle.view(-1), pred.view(-1)):\n",
    "                    conf_mat[a.long(), p.long()] +=1\n",
    "                    \n",
    "            elif problem == 'regression_1':\n",
    "                loss = criterion(output, angle)\n",
    "            \n",
    "            elif problem == 'regression_2' or problem == 'regression_3':\n",
    "                angle = torch.deg2rad(angle.float())\n",
    "                loss = criterion(output, angle)\n",
    "        \n",
    "            elif problem == 'regression_4':\n",
    "                loss = criterion(output, angle)\n",
    "            \"\"\"elif problem == 'regression_4':\n",
    "                outs = torch.sin(output[:, 1])  # Prediction of the sinus\n",
    "                outc = torch.cos(output[:, 0])  # Prediction of the cosine\n",
    "                pred_angle = torch.atan2(outs, outc) # Get the pred_angle in Radians\n",
    "                angle = torch.deg2rad(angle.float())  # Transform the real angle in radians\n",
    "            \n",
    "                loss = criterion(output, angle)\"\"\"\n",
    "                \n",
    "            \"\"\"else:\n",
    "                output = output.reshape(len(output))\n",
    "                cos_output = torch.cos(torch.deg2rad(output.float()))\n",
    "                cos_angle  = torch.cos(torch.deg2rad(angle.float()))\n",
    "                sin_output = torch.sin(torch.deg2rad(output.float()))\n",
    "                sin_angle  = torch.sin(torch.deg2rad(angle.float()))\n",
    "\n",
    "                val_loss += criterion(cos_output, cos_angle) + criterion(sin_output, sin_angle)                \n",
    "                \n",
    "                angle_5 = angle//72\n",
    "                output_5 = output//72\n",
    "                correct_5 += output_5.eq(angle_5).cpu().sum()\n",
    "\n",
    "                angle_2_5 = angle//36\n",
    "                output_2_5 = output//36\n",
    "                correct_2_5 += output_2_5.eq(angle_2_5).cpu().sum()\n",
    "\n",
    "                angle_1 = angle//1\n",
    "                output_1 = output//1\n",
    "                correct_1 += output_1.eq(angle_1).cpu().sum()\n",
    "            \n",
    "                for a, p in zip(angle_5.view(-1), output_5.view(-1)):\n",
    "                    conf_mat[a.long(), p.long()] +=1\n",
    "            \"\"\"\n",
    "    \n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "    confusion_matrix.append(conf_mat)\n",
    "                \n",
    "    if problem == 'classification':\n",
    "        accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "        accuracy_vector.append(accuracy)\n",
    "\n",
    "        print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "                    .format(val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "        \n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        accuracy_5 = 100. * correct_5.to(torch.float32) / len(validation_loader.dataset)\n",
    "        accuracy_2_5 = 100. * correct_2_5.to(torch.float32) / len(validation_loader.dataset)\n",
    "        accuracy_1 = 100. * correct_1.to(torch.float32) / len(validation_loader.dataset)\n",
    "\n",
    "        accuracy_vector.append(accuracy_5)\n",
    "        accuracy_vector.append(accuracy_2_5)\n",
    "        accuracy_vector.append(accuracy_1)        \n",
    "        \n",
    "        print('Validation set: Average loss: {:.4f}, Accuracy 5 : {:.1f}%, Accuracy 2.5 : {:.1f}, Accuracy 1 : {:.1f}\\n'\n",
    "                    .format(val_loss, accuracy_5, accuracy_2_5, accuracy_1))\n",
    "                    \n",
    "        \"\"\"\n",
    "        print(f\"Validation loss: {val_loss}\")\n",
    "        \n",
    "        \n",
    "    '''   \n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    \n",
    "    # At the end of an epoch, print the precision of the current model weight\n",
    "    print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "            .format(val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_prediction_from_img(path, model, device, problem = 'classification'):\n",
    "    \"\"\"Function that take a image of detected centriole\"\"\"\n",
    "    \n",
    "    detectionpath = path[:-4] + '_centriole_detected.tif'\n",
    "    \n",
    "    #Read the image\n",
    "    img = cv2.imread(detectionpath, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    #Extract the coordinate of detected centrioles\n",
    "    ypts, xpts = np.where(img == 1)\n",
    "    \n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    a_list_of_centriole = []\n",
    "    x_shape, y_shape = img.shape[1], img.shape[0] \n",
    "    \n",
    "    xlim, ylim  = x_shape - 16 , y_shape - 16\n",
    "    for i in tqdm(range(len(ypts))):\n",
    "        x, y = xpts[i], ypts[i]\n",
    "\n",
    "        if y > 16 and x > 16 and y < ylim and x < xlim:\n",
    "            #centriole_extracted = img.crop((xpts[i], ypts[i], xpts[i] + 32, ypts[i] + 32))\n",
    "            centriole = img[y-16:y+16, x-16:x+16]\n",
    "            centriole = np.asarray(centriole, dtype = \"uint8\")\n",
    "            centriole = centriole.reshape(1 , 1, 32, 32)\n",
    "            # Inside predictor:\n",
    "            centriole = torch.from_numpy(centriole)\n",
    "            centriole = centriole.float().to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(centriole)\n",
    "\n",
    "            angle = output.max(1)[1]\n",
    "            angle = angle.cpu().numpy()\n",
    "\n",
    "            #print(centriole_extracted)\n",
    "            #angle = predictor(model, centriole_extracted, device, problem = 'classification')\n",
    "            a_list_of_centriole.append(((xpts[i], ypts[i]), angle[0]))\n",
    "            \n",
    "    return a_list_of_centriole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
