{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objective\n",
    "This is the main notebook of the pipeline that will allow detection and prediction of the rootlet from planarian multiciliated cells\n",
    "\n",
    "Note 13 April 2021: Data Vizualization is not implemented but I think that data are saved as a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/raphaelbecquart/git_environment/Planarians/tools/Centriole_Characteristic.ipynb\n",
      "importing Jupyter notebook from /home/raphaelbecquart/git_environment/Planarians/tools/ToolBox.ipynb\n",
      "importing Jupyter notebook from /home/raphaelbecquart/git_environment/Planarians/tools/Midline_Edge_Reformater.ipynb\n",
      "importing Jupyter notebook from /home/raphaelbecquart/git_environment/Planarians/tools/Extract_Experiment_Characteristic.ipynb\n",
      "importing Jupyter notebook from /home/raphaelbecquart/git_environment/Planarians/tools/CNN_Tools.ipynb\n",
      "importing Jupyter notebook from /home/raphaelbecquart/git_environment/Planarians/tools/Graphical_Tools.ipynb\n",
      "importing Jupyter notebook from /home/raphaelbecquart/git_environment/Planarians/tools/Analysis_Tools.ipynb\n",
      "importing Jupyter notebook from /home/raphaelbecquart/git_environment/Planarians/tools/Centriole_Detection.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Allow importation of the others notebook\n",
    "import import_ipynb\n",
    "\n",
    "# pyTorch: module for the neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# load excel files \n",
    "# note 13 April 2021: the module might be deprecated => yes only for .xls \n",
    "#import xlrd - Using pylightxl instead\n",
    "import pylightxl as xl\n",
    "\n",
    "# time tools\n",
    "from time import time, asctime\n",
    "\n",
    "# module that list all files in a input directory\n",
    "from glob import glob\n",
    " \n",
    "# module that open/save data as csv\n",
    "import csv\n",
    "\n",
    "#import asyncio   # note 13/04/2021, this module was already anotated: might be useless\n",
    "\n",
    "# Data Vizualisation module\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "# helper function \n",
    "# note 13/04/2021 instead of * each function should be load independently\n",
    "from tools.Centriole_Characteristic import *\n",
    "from tools.Extract_Experiment_Characteristic import *\n",
    "from tools.CNN_Tools import *\n",
    "from tools.Graphical_Tools import *\n",
    "from tools.Centriole_Detection import *\n",
    "\n",
    "#from tools.Worm_Segmentation import extract_worm_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 63/100x anti-rootletin image(s) and excel file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./to_analyse/160331_Vfl1_rootletin_full_10.tif'] ['./to_analyse/160331_Vfl1_rootletin_full_10.xlsm']\n"
     ]
    }
   ],
   "source": [
    "# This cell load the preprocess 100x images and the corresponding excel file \n",
    "# Immunofluorescence images acquired at objective 63x or 100x \n",
    "# Excel file with midline and edge coordinate, X- and Y- shift\n",
    "\n",
    "# 2 options are available: \n",
    "optionChosen = 2\n",
    "\n",
    "# OPTION 1:\n",
    "# analyzis of all data in a folder\n",
    "if optionChosen == 1:\n",
    "    tif_list = glob('./to_analyse/*.tif')\n",
    "    xls_list = glob('./to_analyse/*.xlsm')\n",
    "\n",
    "# OPTION 2:\n",
    "# analyse only a specific file, put the path, and uncomment the two lines below:\n",
    "elif optionChosen == 2:\n",
    "    file_name = './to_analyse/160331_Vfl1_rootletin_full_10' #enter full path + file name without extension. \n",
    "    tif_list = [file_name + '.tif']                #User inputs file name only => by definition xlsm & tif share the same name.\n",
    "    xls_list = [file_name + '.xlsm']\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print('Option provided was not understood')\n",
    "\n",
    "print(tif_list, xls_list)\n",
    "\n",
    "# WARNING: \n",
    "# I'm not sure to put any Quality Check in the script, make sure that the name of both file\n",
    "# .xlsm and .tif share the same name at the exception of the extension\n",
    "\n",
    "# Note: \n",
    "# It's better to put the full path of the file, the './my_directory' is the linux equivalent of 'c:/my_directory'\n",
    "# If Option 2: keep the bracket and the apostrophe ['./whateverYouNeed/xxx.xslm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Cyril the 13/04/2021\n",
    " \n",
    "I annotated the code but i didn't check if it work.\n",
    " \n",
    "From what i looked so far, their is currently no possibility to load some already pre process data (detect centriole one day then predict their angle an other day). This might be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 14 23:35:57 2021\n",
      "Exl file loaded: ./to_analyse/160331_Vfl1_rootletin_full_10.xlsm\n",
      "Tif file loaded: ./to_analyse/160331_Vfl1_rootletin_full_10.tif\n",
      "{'file_name': './to_analyse/160331_Vfl1_rootletin_full_10.xlsm', 'image_shift': {'x': 2310, 'y': 885}, 'worm_midline': {'x': '', 'y': ''}, 'worm_edge': {'x': 3192, 'y': 3204.9797}, 'worm_orientation': 'droite', 'microscope_magnification': 100, 'microscope_pixel_size_in_nm': 64.5, 'image_magnification': 100, 'image_pixel_size_in_um': 0.0645, 'worm_integrity': 'entier', 'fit_edge_and_midline': 'non', 'optional_width': 'non', 'approximate_real_distance': 'oui', 'approximative_length/with': 2.5, 'left-right_difference': 'oui'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b695f29e8bcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mnewY_mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_mid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_edg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mnewY_edg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_edg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "# THIS IS A TESTING CELL. NOT A DUPLICATE OF THE NEXT CELL.\n",
    "\n",
    "# Do you want to save as image the intermediate result (DOG, find_maxima, DOG+find_maxima)\n",
    "# It's memory consuming but since this algorithm is very slow it's better to save the result\n",
    "# especially for publication purpose\n",
    "SAVE_INTERMEDIATE_IMG = True\n",
    "\n",
    "# Do you want to load the 'skeleton' of the worm (midline & edge)\n",
    "LOAD_MIDLINE_AND_EDGE_FROM_EXCEL = True # This should not be ther\n",
    "\n",
    "# Loop that will analyze one by one all the file define above.\n",
    "for pathExcel, pathImg_100x in zip(xls_list, tif_list):\n",
    "    \n",
    "    # print the time when the file start to be compute and the name of both file\n",
    "    print(f\"{asctime()}\")\n",
    "    print(f\"Exl file loaded: {pathExcel}\")\n",
    "    print(f\"Tif file loaded: {pathImg_100x}\") \n",
    "\n",
    "# MIDLINE AND WORM EDGE    \n",
    "    \n",
    "# 13/04/2021: In the future 2 options might be available: \n",
    "# Either the midline and edge will be draw manually with ImageJ\n",
    "# Or an automatic algorithm will do the job\n",
    "# Currently the automatic version is not available\n",
    "\n",
    "    # Load Midline and Edge coordinates from a 'classical' excel file\n",
    "    if LOAD_MIDLINE_AND_EDGE_FROM_EXCEL:\n",
    "# 13/04/2021: To Raphael: perfect example of why it's better to load function individually and not with a *\n",
    "# it have been easier for me to find it and know what function is doing exactly\n",
    "\n",
    "# 13/04/2021: it looks like the get_xls_values() function open the excel file and load the coordinates \n",
    "# for midline and edge in this excel file\n",
    "        db = get_xls_values(pathExcel)\n",
    "        print(db)\n",
    "        x_mid = db['worm_midline']['x']\n",
    "        y_mid = db['worm_midline']['y']\n",
    "        x_edg = db['worm_edge']['x']\n",
    "        y_edg = db['worm_edge']['y']\n",
    "        # Invert the y axis for edge and midline\n",
    "# 13/04/2021: If i remember well, that's require because imageJ have an invertex y axis (the (0,0) coordinate\n",
    "# is in top left corner, and we want it bottom left corner)\n",
    "        newY_mid, newY_edg = [], []  #the code below throws a TypeError. Need to adapt to optionchosen ==2.\n",
    "        for y in y_mid:\n",
    "            newY_mid.append(-y)\n",
    "\n",
    "        for y in y_edg:\n",
    "            newY_edg.append(-y)\n",
    "\n",
    "        # 'skeleton' of the worm\n",
    "        worm = [x_mid, newY_mid, x_edg, newY_edg ]\n",
    "print(worm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-14-1017a856537d>, line 306)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-1017a856537d>\"\u001b[0;36m, line \u001b[0;32m306\u001b[0m\n\u001b[0;31m    #plt.show()\u001b[0m\n\u001b[0m               \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "# Do you want to save as image the intermediate result (DOG, find_maxima, DOG+find_maxima)\n",
    "# It's memory consuming but since this algorithm is very slow it's better to save the result\n",
    "# especially for publication purpose\n",
    "SAVE_INTERMEDIATE_IMG = True\n",
    "\n",
    "# Do you want to load the 'skeleton' of the worm (midline & edge)\n",
    "LOAD_MIDLINE_AND_EDGE_FROM_EXCEL = True # This should not be ther\n",
    "\n",
    "# Loop that will analyze one by one all the file define above.\n",
    "for pathExcel, pathImg_100x in zip(xls_list, tif_list):\n",
    "    \n",
    "    # print the time when the file start to be compute and the name of both file\n",
    "    print(f\"{asctime()}\")\n",
    "    print(f\"Exl file loaded: {pathExcel}\")\n",
    "    print(f\"Tif file loaded: {pathImg_100x}\") \n",
    "\n",
    "    \n",
    "\n",
    "    # Are you just testing the angle compensation?\n",
    "    Test_Angle_Compensation = False\n",
    "\n",
    "    path_img_10x   = './full_worm/C1-180417_Dvl1&2_Odf2-injection_root_17dpa_10x_Full_1.tif'\n",
    "\n",
    "    problem = 'classification'\n",
    "\n",
    "\n",
    "# MIDLINE AND WORM EDGE    \n",
    "    \n",
    "# 13/04/2021: In the future 2 options might be available: \n",
    "# Either the midline and edge will be draw manually with ImageJ\n",
    "# Or an automatic algorithm will do the job\n",
    "# Currently the automatic version is not available\n",
    "\n",
    "    # Load Midline and Edge coordinates from a 'classical' excel file\n",
    "    if LOAD_MIDLINE_AND_EDGE_FROM_EXCEL:\n",
    "\n",
    "# 13/04/2021: To Raphael: perfect example of why it's better to load function individually and not with a *\n",
    "# it have been easier for me to find it and know what function is doing exactly\n",
    "\n",
    "# 13/04/2021: it looks like the get_xls_values() function open the excel file and load the coordinates \n",
    "# for midline and edge in this excel file\n",
    "        db = get_xls_values(pathExcel)\n",
    "\n",
    "        x_mid = db['worm_midline']['x']\n",
    "        y_mid = db['worm_midline']['y']\n",
    "        x_edg = db['worm_edge']['x']\n",
    "        y_edg = db['worm_edge']['y']\n",
    "\n",
    "        # Invert the y axis for edge and midline\n",
    "# 13/04/2021: If i remember well, that's require because imageJ have an invertex y axis (the (0,0) coordinate\n",
    "# is in top left corner, and we want it bottom left corner)\n",
    "        newY_mid, newY_edg = [], []\n",
    "        for y in y_mid:\n",
    "            newY_mid.append(-y)\n",
    "\n",
    "        for y in y_edg:\n",
    "            newY_edg.append(-y)\n",
    "\n",
    "        # 'skeleton' of the worm\n",
    "        worm = [x_mid, newY_mid, x_edg, newY_edg ]\n",
    "\n",
    "\n",
    "    # Automatic characterization of the midline and the edge\n",
    "    ## So far (17 November 2020) do not work at all. \n",
    "    ## Ideas: size of the image, contrast (rm background per example)\n",
    "    else:\n",
    "        midline, edge = extract_worm_edge(path_img_10x, quantile = 0.01)\n",
    "        worm = [midline[0], midline[1], edge[0], edge[1]]\n",
    "\n",
    "    \n",
    "    # Reformat midline and Edge in a given number of segment and subsegment\n",
    "    midline_final = aggregate_segment_char(x_mid, newY_mid, \n",
    "                                           x_edg, newY_edg, \n",
    "                                           n_midline_seg = 50, \n",
    "                                           n_sub_segment = 25, \n",
    "                                           n_edge_seg = 200)\n",
    "\n",
    "\n",
    "    print(f'{asctime()}: Edge and Midline reformated')\n",
    "\n",
    "# 13/04/2021: improvment possibility of the previous function: perform an interpolation of the midline\n",
    "# instead of using segment\n",
    "# might be possible to do it as well for the edge, but perhaps harder because edge is circular\n",
    "\n",
    "\n",
    "\n",
    "# CENTRIOLES IDENTIFICATION\n",
    "    \n",
    "    # load the 100x image using OpenCV\n",
    "    img = cv2.imread(pathImg_100x, cv2.IMREAD_UNCHANGED)\n",
    "    print(f'{asctime()}: Image Loaded')\n",
    "\n",
    "    # Compute differential of Gaussian then Otsu thresholding to try to get a mask of the centriole\n",
    "    # return a binary image\n",
    "    dog_img = dog_and_otsu(img)\n",
    "    \n",
    "    if SAVE_INTERMEDIATE_IMG:\n",
    "        img_to_save = Image.fromarray(dog_img)\n",
    "        newPath = pathImg_100x[:-4] + '_dog_otsu.tif'\n",
    "        img_to_save.save(newPath)\n",
    "        \n",
    "    print(f'{asctime()}: Dog & Otsu computed ')\n",
    "\n",
    "    \n",
    "    # detect centriole using find_maxima algorithm \n",
    "    # note: find_maxima() is the implementation of the find_maxima module in imageJ\n",
    "    # return a binary image\n",
    "    find_maxima_img = find_maxima(img)\n",
    "    \n",
    "    if SAVE_INTERMEDIATE_IMG:\n",
    "        img_to_save = Image.fromarray(find_maxima_img)\n",
    "        newPath = pathImg_100x[:-4] + '_find_maxima.tif'\n",
    "        img_to_save.save(newPath)\n",
    "        \n",
    "    print(f'{asctime()}: Find Maxima Computed')\n",
    "\n",
    "    \n",
    "    # combine the 2 previous approaches to get the final \n",
    "    # return a binary image\n",
    "    combine_img = dog_img*find_maxima_img\n",
    "    \n",
    "    if SAVE_INTERMEDIATE_IMG:\n",
    "        img_to_save = Image.fromarray(combine_img)\n",
    "        newPath = pathImg_100x[:-4] + '_centriole_detected.tif'\n",
    "        img_to_save.save(newPath)\n",
    "    print(f'{asctime()}: Centriole detected')\n",
    "\n",
    "    \n",
    "# 13/04/2021: I'm almost sure that all the code above this comment work fine.\n",
    "# Due to some comment in the code, it looks like the code below will not work\n",
    "\n",
    "# ANGLE PREDICITON OF THE CENTRIOLE\n",
    "\n",
    "# The prediction is perfomed thanks to a neural network implemented in Python using the pyTorch package\n",
    "\n",
    "    # Define where the prediction will be perform (on cpu or on gpu (graphic card))\n",
    "    # using the gpu require an Nvidia graphic card with cuda installed\n",
    "#13/04/2021: to train a model it's mandatory to use CUDA, to predict the orientation of 'only' 100k\n",
    "# i don't know how much time it will take to use a cpu. using google Colab might be mandatory\n",
    "    if torch.cuda.is_available():                                  \n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    # Loading the Neural Network (VGG_Schmidtea) and the Weight of the network ()\n",
    "#13/04/2021: only classification is working, the path below do not exist, the appropriate weigth might be:\n",
    "# './weight/VGG_schmidtea_weight_classification_noReLu_80percent_classification_n72.pth'\n",
    "    if problem == 'classification':\n",
    "        model = VGG_Schmidtea(n_classes = 72).to(device)\n",
    "        model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_classification.pth', map_location = device))\n",
    "    else:\n",
    "        model = VGG_Schmidtea(n_classes = 1).to(device)\n",
    "        model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_regression.pth', map_location = device))\n",
    "\n",
    "    # Put the model in evaluation/prediction mode\n",
    "    model.eval()\n",
    "    \n",
    "# 13/04/2021: End of my code review, the code below need to be checked properly \n",
    "############################################################################################################\n",
    "    # I don't know how the centriole image will come but to do the prediction:\n",
    "\n",
    "    # Extraction of coordinates where centrioles are\n",
    "    ypts, xpts = np.where(combine_img == 1)\n",
    "\n",
    "    a_list_of_centriole = []\n",
    "\n",
    "    x_shape, y_shape = img.shape[1], img.shape[0] \n",
    "    xlim, ylim  = x_shape - 16 , y_shape - 16\n",
    "    for i in range(len(ypts)):\n",
    "        x, y = xpts[i], ypts[i]\n",
    "\n",
    "        if y > 16 and x > 16 and y < ylim and x < xlim:\n",
    "            #centriole_extracted = img.crop((xpts[i], ypts[i], xpts[i] + 32, ypts[i] + 32))\n",
    "            centriole = img[y-16:y+16, x-16:x+16]\n",
    "            centriole = np.asarray(centriole, dtype = \"uint8\")\n",
    "            centriole = centriole.reshape(1 , 1, 32, 32)\n",
    "            # Inside predictor:\n",
    "            centriole = torch.from_numpy(centriole)\n",
    "            centriole = centriole.float().to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(centriole)\n",
    "\n",
    "            angle = output.max(1)[1]\n",
    "            angle = angle.numpy()\n",
    "\n",
    "            #print(centriole_extracted)\n",
    "            #angle = predictor(model, centriole_extracted, device, problem = 'classification')\n",
    "            a_list_of_centriole.append(((xpts[i], ypts[i]), angle[0]))\n",
    "\n",
    "\n",
    "    print(f'{asctime()}: Centrioles angle predicted and compensated')\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "    # CENTRIOLE REPOSITIONNING ET REORIENTATION\n",
    "    ###############################################\n",
    "\n",
    "    shiftX = db['image_shift']['x']\n",
    "    shiftY = db['image_shift']['y']\n",
    "    shifted_centriole_list = []\n",
    "\n",
    "    for a_centriole in a_list_of_centriole:\n",
    "        xShifted = a_centriole[0][0] + shiftX\n",
    "        yShifted = a_centriole[0][1] + shiftY\n",
    "        if problem == 'classification':\n",
    "            shifted_centriole_list.append(((xShifted, -yShifted),a_centriole[1]*5+2.5))\n",
    "        else:\n",
    "            shifted_centriole_list.append(((xShifted, -yShifted),a_centriole[1]))\n",
    "\n",
    "\n",
    "\n",
    "    reoriented_centriole = []\n",
    "    for a_centriole in shifted_centriole_list:\n",
    "        tmp_list = list(centriole_characterizator(a_centriole, midline_final))\n",
    "        if db['worm_orientation'] == 'gauche' or db['worm_orientation'] == 'left':\n",
    "            tmp_list[-2] = 1 - tmp_list[-2]\n",
    "            tmp_list[-1] = math.degrees(math.atan2(-math.sin(math.radians(tmp_list[-1])), -math.cos(math.radians(tmp_list[-1]))))\n",
    "        tmp_list.insert(1,a_centriole[0][0])\n",
    "        tmp_list.insert(2,a_centriole[0][1])\n",
    "\n",
    "        reoriented_centriole.append(tmp_list)\n",
    "\n",
    "    # Save\n",
    "    newPath = pathImg_100x[:-4] + '_DATA.csv'\n",
    "    with open(newPath, 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(reoriented_centriole)\n",
    "\n",
    "\n",
    "    print(f'{asctime()}: Centriole Dataset reformated')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #######################################################\n",
    "    # Graphical representation of the results\n",
    "    # Code above is not mandatory\n",
    "    #######################################################\n",
    "    \n",
    "    # If you want to see some specific centrioles, add them in the list\n",
    "    list_of_desired_centriole = [0]\n",
    "\n",
    "    # If you want to see the location of a specific coordinate (Write None if you don't want to see them )\n",
    "    X_coordinate = None\n",
    "    Y_coordinate = None\n",
    "\n",
    "    save_path = pathImg_100x[:-4] + '_schema.tif'\n",
    "    Worm_And_Centriole(reoriented_centriole, worm, list_of_desired_centriole, (X_coordinate, Y_coordinate), save = True, path = pathImg_100x[:-4])\n",
    "    \n",
    "    # Print The graph (worms segmented in 5 antero-posterior parts) + moving average + cstd\n",
    "    for i in range(5):\n",
    "        print_a_antero_posterior_result(reoriented_centriole, i, n_ante_post_segment = 5, a_lat_size = 0.1, a_lat_step = 0.05, save = True, path = pathImg_100x[:-4])\n",
    "        \n",
    "    # Overlap the analysed image with the identified and analyzed centriole represented as an arrow indicating the predicted angle\n",
    "    # The starting point of the arrow is the origin of the detected centriole\n",
    "    # The Ending point indicate the predicted orientation of the centriole\n",
    "\n",
    "    save_figure = True\n",
    "\n",
    "    # Each color correspond to a class of 5째\n",
    "    # So far the color or 'randomly' attributed for each class\n",
    "\n",
    "    # Define the length of the arrow\n",
    "    arrowLen = 5\n",
    "\n",
    "    # Compute as X/Y coordinates the property of the arrow\n",
    "    # WARNING: 18/11/2020. FOR AN UNKNOWN REASON, the angle is rotated by 90째 -> I need to check why\n",
    "    DATA = []\n",
    "\n",
    "    for i in a_list_of_centriole:\n",
    "        angle = i[1] + 90\n",
    "        x = i[0][0]\n",
    "        y = i[0][1]\n",
    "        new_coord = [x-arrowLen*math.cos(math.radians(angle)), y-arrowLen*math.sin(math.radians(angle)), x+arrowLen*math.cos(math.radians(angle)), y+arrowLen*math.sin(math.radians(angle)), angle]\n",
    "        DATA.append(new_coord)\n",
    "\n",
    "    DATA = np.array(DATA)\n",
    "\n",
    "    cmap = plt.cm.jet\n",
    "    cNorm  = colors.Normalize(vmin=np.min(DATA[:,4]), vmax=np.max(DATA[:,4]))\n",
    "    scalarMap = cmx.ScalarMappable(norm=cNorm,cmap=cmap)\n",
    "\n",
    "    plt.figure(figsize=(100,50))\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    for idx in range(0,len(DATA[:,1])):\n",
    "        colorVal = scalarMap.to_rgba(DATA[idx,4])\n",
    "        plt.arrow(DATA[idx,0],  #x1\n",
    "                  DATA[idx,1],  # y1\n",
    "                  DATA[idx,2]-DATA[idx,0], # x2 - x1\n",
    "                  DATA[idx,3]-DATA[idx,1], # y2 - y1\n",
    "                  color=colorVal)\n",
    "    if save_figure: \n",
    "        savePath = pathImg_100x[:-4] + '_Detected_Angle.tif'\n",
    "        plt.savefig(savePath)\n",
    "        \n",
    "    with open('./file_treated.csv', 'a', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(tif_list[i])\"\"\"\n",
    "    print(f\"{asctime()}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a_list_of_centriole' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a51bf294951f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mDATA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma_list_of_centriole\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mangle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a_list_of_centriole' is not defined"
     ]
    }
   ],
   "source": [
    "# Overlap the analysed image with the identified and analyzed centriole represented as an arrow \n",
    "# indicating the predicted angle\n",
    "# The starting point of the arrow is the origin of the detected centriole\n",
    "# The Ending point indicate the predicted orientation of the centriole\n",
    "\n",
    "save_figure = True\n",
    "show_figure = True\n",
    "\n",
    "# Each color correspond to a class of 5째\n",
    "# So far the color or 'randomly' attributed for each class\n",
    "\n",
    "# Define the length of the arrow\n",
    "arrowLen = 5\n",
    "\n",
    "# Compute as X/Y coordinates the property of the arrow\n",
    "# WARNING: 18/11/2020. FOR AN UNKNOWN REASON, the angle is rotated by 90째 -> I need to check why\n",
    "DATA = []\n",
    "\n",
    "for i in a_list_of_centriole:\n",
    "    angle = i[1] + 90\n",
    "    x = i[0][0]\n",
    "    y = i[0][1]\n",
    "    new_coord = [x-arrowLen*math.cos(math.radians(angle)), y-arrowLen*math.sin(math.radians(angle)), x+arrowLen*math.cos(math.radians(angle)), y+arrowLen*math.sin(math.radians(angle)), angle]\n",
    "    DATA.append(new_coord)\n",
    "    \n",
    "DATA = np.array(DATA)\n",
    "\n",
    "cmap = plt.cm.jet\n",
    "cNorm  = colors.Normalize(vmin=np.min(DATA[:,4]), vmax=np.max(DATA[:,4]))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm,cmap=cmap)\n",
    "\n",
    "plt.figure(figsize=(100,50))\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "for idx in range(0,len(DATA[:,1])):\n",
    "    colorVal = scalarMap.to_rgba(DATA[idx,4])\n",
    "    plt.arrow(DATA[idx,0],  #x1\n",
    "              DATA[idx,1],  # y1\n",
    "              DATA[idx,2]-DATA[idx,0], # x2 - x1\n",
    "              DATA[idx,3]-DATA[idx,1], # y2 - y1\n",
    "              color=colorVal)\n",
    "if save_figure: \n",
    "    savePath = pathImg_100x[:-4] + '_Detected_Angle.tif'\n",
    "    plt.savefig(savePath)\n",
    "\n",
    "if show_figure:\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical Representation of the worms and the analyzed centrioles\n",
    "# If you want to see some specific centrioles, add them in the list\n",
    "list_of_desired_centriole = [0]\n",
    "\n",
    "# If you want to see the location of a specific coordinate (Write None if you don't want to see them )\n",
    "X_coordinate = None\n",
    "Y_coordinate = None\n",
    "\n",
    "save_path = pathImg_100x[:-4] + '_schema.tif'\n",
    "Worm_And_Centriole(reoriented_centriole, worm, list_of_desired_centriole, (X_coordinate, Y_coordinate), save_path, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of the results \n",
    "for i in range(5):\n",
    "    print_a_antero_posterior_result(reoriented_centriole, i, n_ante_post_segment = 5, a_lat_size = 0.1, a_lat_step = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t connard\n"
     ]
    }
   ],
   "source": [
    "print('\\t connard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
